# ğŸš€ AI File Search

**AI File Search** ist eine moderne, lokale Desktop-Suchmaschine fÃ¼r deine Dokumente. Sie nutzt kÃ¼nstliche Intelligenz, um Inhalte nicht nur nach Stichworten, sondern nach **Bedeutung** (semantische Suche) zu finden.

Die Anwendung lÃ¤uft **zu 100% lokal** auf deinem PC. Deine Daten verlassen niemals deinen Computer.

## âœ¨ Features

* **Intelligente Suche:** Findet Dokumente anhand der Bedeutung, auch wenn das genaue Schlagwort nicht enthalten ist (Vektor-Suche).
* **KI-Zusammenfassungen:** Erstellt automatisch kurze Zusammenfassungen fÃ¼r jedes gefundene Dokument.
* **UnterstÃ¼tzte Formate:** PDF, Word (.docx) und Textdateien (.txt).
* **Modernes UI:** Schickes Design mit Dark/Light Mode UnterstÃ¼tzung (basierend auf CustomTkinter).
* **Direktzugriff:** Dateien Ã¶ffnen oder direkt im Explorer anzeigen lassen.
* **PrivatsphÃ¤re:** Nutzt Ollama lokal â€“ keine Cloud, kein Internet nÃ¶tig.

## ğŸ› ï¸ Voraussetzungen

Bevor du startest, stelle sicher, dass folgende Software installiert ist:

1. **Python** (Version 3.10 oder neuer)
2. **Ollama**: Die KI-Engine im Hintergrund. [Hier herunterladen](https://ollama.com).

### KI-Modelle laden

Nach der Installation von Ollama musst du einmalig die benÃ¶tigten Modelle herunterladen. Ã–ffne dein Terminal (Eingabeaufforderung) und fÃ¼hre aus:

```bash
ollama pull llama3.2
ollama pull nomic-embed-text

```

* `llama3.2`: Wird fÃ¼r die Zusammenfassungen genutzt.
* `nomic-embed-text`: Wird fÃ¼r die mathematische Vektor-Suche genutzt.

## ğŸ“¦ Installation

1. **Repository klonen oder Dateien herunterladen:**
Stelle sicher, dass `main.py`, `config.py`, `search_backend.py` und `file_reader.py` in einem Ordner liegen.
2. **AbhÃ¤ngigkeiten installieren:**
Ã–ffne das Terminal in diesem Ordner und fÃ¼hre aus:
```bash
pip install -r requirements.txt

```



## ğŸš€ Starten der App

FÃ¼hre einfach die Hauptdatei aus:

```bash
python main.py

```

## ğŸ“– Bedienungsanleitung

1. **Ordner wÃ¤hlen:** Klicke oben auf **"ğŸ“‚ Ordner wÃ¤hlen & Scannen"**. WÃ¤hle deinen Dokumentenordner aus.
2. **Warten:** Die App scannt nun alle Dateien (PDF/Word), liest den Text und berechnet die Vektoren. Dies passiert beim ersten Mal etwas langsamer, danach werden nur neue Dateien verarbeitet.
3. **Suchen:** Gib unten deine Suchanfrage ein (z.B. *"Rechnung Handwerker"* oder *"Projektplanung 2024"*) und drÃ¼cke Enter.
4. **Ergebnisse:** Klicke auf **"ğŸ“„ Ã–ffnen"**, um das Dokument zu lesen, oder **"ğŸ“‚ Ordner"**, um den Speicherort im Explorer anzuzeigen.

## âš™ï¸ Konfiguration

Du kannst Einstellungen in der Datei `config.py` anpassen:

* **Modelle Ã¤ndern:** Falls du andere Ollama-Modelle nutzen willst.
* **Design:** Ã„ndere `COLOR_THEME` (z.B. auf "green" oder "dark-blue").
* **FenstergrÃ¶ÃŸe:** Passe `APP_SIZE` an.

## ğŸ“‚ Projektstruktur

Das Projekt ist sauber nach ZustÃ¤ndigkeiten getrennt:

* `main.py`: Das grafische Benutzerinterface (CustomTkinter).
* `search_backend.py`: Verwaltet den Index und die Kommunikation mit der KI.
* `file_reader.py`: Liest Texte aus PDF- und Word-Dateien.
* `config.py`: Zentrale Einstellungen.
* `search_index.json`: Hier wird der Such-Index (die "Datenbank") gespeichert.

## â“ Troubleshooting

**Fehler: "Model not found"**
Stelle sicher, dass du `ollama pull ...` ausgefÃ¼hrt hast und die Namen in der `config.py` exakt stimmen.

**Fehler: Keine Zusammenfassung / 0% Match**
Das passiert oft bei eingescannten PDFs (Bilder). Die App benÃ¶tigt Text, der markierbar ist. FÃ¼r Bild-PDFs wÃ¤re eine OCR-Erweiterung nÃ¶tig.

---
